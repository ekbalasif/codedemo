<html lang="en">

<head>
  <meta charset="utf-8">
  <title>BTAS 2019</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/favicon.png" rel="icon">
  <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css" rel="stylesheet">

  <!-- =======================================================
    Theme Name: TheEvent
    Theme URL: https://bootstrapmade.com/theevent-conference-event-bootstrap-template/
    Author: BootstrapMade.com
    License: https://bootstrapmade.com/license/
  ======================================================= -->
</head>

<body>

  <!--==========================
    Header
  ============================-->
  <header id="header">
    <div class="container">

      <div id="logo" class="pull-left">
        <!-- Uncomment below if you prefer to use a text logo -->
         <!-- <h1><a href="#main">C<span>o</span>nf</a></h1> -->
        <a href="#intro" class="scrollto"><img src="img/1logo.png" alt="" title="" style="height: 95px; width: 120px; padding-bottom: 18px; padding-right: -15px"></a>
        <!-- <h3 style="font-family: Times new;font-size: 54px;font-weight: bold;color: #0e1b4d;text-align: left;">BTAS 2019</h3> -->
      </div>

      <nav id="nav-menu-container">
        <ul class="nav-menu">
          <li class="menu-active"><a href="index.html">Home</a></li>
          <li><a href="organizers.html">Organizers</a></li>
          <li><a href="importantDates.html">Important Dates</a></li>
          <li><a href="submission.html">Submission</a></li>
           
          <li><a href="Program.html">Program</a></li>
          <li><a href="logistics.html">Logistics</a></li>
          <li><a href="sponsors.html">Sponsors</a></li>
           <img src="img/sponsors/9.jpg" class="img-fluid" alt="" style="height: 90px; width: 179px; padding-bottom: 30px; padding-left: 35px;">
            
          <!-- <li><a href="#venue">Venue</a></li>
          <li><a href="#hotels">Hotels</a></li>
          <li><a href="#gallery">Gallery</a></li> -->
          <!-- <li><a href="#sponsors">Sponsors</a></li> -->
          <!--<li><a href="#contact">Contact</a></li> -->
          <!-- <li class="buy-tickets"><a href="#buy-tickets">Buy Tickets</a></li>
        </ul> -->
      </nav><!-- #nav-menu-container -->
    </div>
  </header><!-- #header -->

   

  <main id="main">


    <div class="row">
    
    <div class="col-lg-4"  style='padding-right:0px;border-right: 5px solid red;'>
      <section id="speakers" class="wow fadeInUp">
      <div class="container" style='position: fixed;'>
        <h3>Program</h3>
        <ul>
          <li><a href="#ap">Accepted Papers</a></li>
          <li><a href="#cfd">Call for Demonstrations</a></li>
          
          <li><a href="#com1">Competitions</a></li>
          <li><a href="#doctoral">Doctoral Consortium</a></li>
          <!-- <li><a href="#mainc">Main Conference</a></li> -->
          <li><a href="#cfp">Special Session - Call for papers</a></li>
          <li><a href="#tutorials">Tutorials</a></li>
          </ul>
           
      </div>
      </section>
    </div>
      

    <div class="col-lg-8"  style='padding-right:15px;background: #080f5b;'>
      <br/>

<section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="ap">
          <div class="section-header" >
          <h2 style="text-align: center;">LIST OF ACCEPTED PAPERS</h2>
          </div>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
          <ul><li>
            <b>Make the Bag Disappear: Carrying Status-invariant Gait-based Human Age Estimation using Parallel Generative Adversarial Networks.</b></br>
          Xiang Li; Yasushi Makihara; Chi Xu; Prof. Yasushi Yagi; Mingwu Ren</li></br>
          <li><b>Cosmetic-Aware Makeup Cleanser</b></br>
          Yi Li; Huaibo Huang; Junchi Yu; Ran He; Tieniu Tan</li></br>  

          <li><b>A Genetic Algorithm Enabled Similarity-Based Attack on Cancellable Biometrics.</b></br>
          Xingbo Dong; Zhe Jin; Andrew Beng Jin Teoh </li></br>
           
<li><b>Unconstrained Thermal Hand Segmentation.</b></br>
          Ewelina Bartuzi; Mateusz M Trokielewicz </li></br>
<li><b>An End-to-End Convolutional Neural Network for ECG-Based Biometric Authentication.</b></br>
          João R Pinto; Jaime Cardoso </li></br>
<li><b>The Effect of Broad and Specific Demographic Homogeneity on the Imposter Distributions and False Match Rates in Face Recognition Algorithm Performance.</b></br>
          John J. Howard; Yevgeniy Sirotin; Arun Vermury </li></br>
<li><b>Hybrid Dictionary Learning and Matching for Video-based Face Verification.</b></br>
          Jingxiao Zheng; Jun-Cheng Chen; Vishal Patel; Carlos Castillo; Rama Chellappa  </li></br>
<li><b>Reliable Age and Gender Estimation from Face Images: Stating the Confidence of Model Predictions.</b></br>
          Philipp Terhörst; Marco Huber; Jan Kolf; Ines Zelch; Naser Damer; Florian Kirchbuchner; Arjan Kuijper </li></br>
<li><b>Gaze-angle Impact on Iris Segmentation using CNNs.</b></br>
          Ehsaneddin Jalilian; Andreas Uhl</li></br>
<li><b>Rotation Invariant Finger Vein Recognition.</b></br>
          Bernhard Prommegger; Andreas Uhl </li></br>
<li><b>User profiling using sequential mining over web elements.</b></br>
          Matan Levi; Itay Hazan </li></br>
<li><b>Palmprint Recognition Using Realistic Animation Aided Data Augmentation.</b></br>
         Pranjal Swarup; Wai-Kin Adams Kong  </li></br>
<li><b>Effects of Postmortem Decomposition on Face Recognition.</b></br>
          David  Bolme; David Cornett; Dawnie Steadman; Kelly Sauerwein; Tiffany Saul </li></br>
<li><b>How to Save Your Face: a Facial Recognition Method Robust Against Image Reconstruction.</b></br>
          Marcin Plata; Piotr Syga; Marek Klonowski </li></br>
<li><b>Finger-Vein Template Protection based on Alignment-Free Hashing.</b></br>
         Simon Kirchgasser; Zhe Jin; Yenlung Lai; Andreas Uhl </li></br>
<li><b>Perception of Image Features in Post-Mortem Iris Recognition: Humans vs Machines.</b></br>
         Adam Czajka; Mateusz M Trokielewicz; Piotr Maciejewicz </li></br>
<li><b>Cross-sensor iris recognition using adversarial strategy and sensor-specific information.</b></br>
          Jianze Wei; Yunlong Wang; Xiang Wu; Zhaofeng He; Ran He; Zhenan Sun  </li></br>
<li><b>Deep Learning-Based Feature Extraction in Iris Recognition: Use Existing Models, Fine-tune or Train From Scratch?.</b></br>
          Aidan Boyd; Adam Czajka; Kevin Bowyer  </li></br>
<li><b>Securing CNN Model and Face Template using Blockchain.</b></br>
          Akhil Goel; Akshay Agarwal; Mayank Vatsa; Richa Singh; Nalini Ratha</li></br>
<li><b>LC-DECAL: Label Consistent Deep Collaborative Learning for Face Recognition.</b></br>
          Lamha Goel; Mayank Vatsa; Richa Singh </li></br>
<li><b>Identity-Aware Deep Face Hallucination via Adversarial Face Verification.</b></br>
          Hadi Kazemi; Fariborz Taherkhani; Nasser Nasrabadi </li></br>
<li><b>A-LINK: Recognizing Disguised Faces via Active Learning based Inter-Domain Knowledge.</b></br>
          Anshuman Suri; Mayank Vatsa; Richa Singh </li></br>
<li><b>Eye Movements Biometrics: a Bibliometric Analysis from 2004 to 2018.</b></br>
          Antonio Ricardo Alexandre Brasil ; Jefferson Andrade; Karin S Komati  </li></br>
<li><b>ThirdEye: Triplet Based Iris Recognition without Normalization.</b></br>
          Sohaib Ahmad; Benjamin Fuller</li></br>
<li><b>MobiFace: A Lightweight Deep Learning Face Recognition on Mobile Devices.</b></br>
          Chi Nhan Duong; Kha Gia Quach; Ibsa K Jalata; Ngan Le; Khoa Luu </li></br>
<li><b>Realistic Dreams: Cascaded Enhancement of GAN-generated Images with an Example in Face Morphing Attacks.</b></br>
          Naser Damer; Fadi Boutros; Alexandra Moseguí Saladié; Florian Kirchbuchner; Arjan Kuijper </li></br>
<li><b>Robust Subject-invariant Feature Learning for Ocular Biometrics in Visible Spectrum.</b></br>
          Sai Narsi Reddy Donthi Reddy; Ajita Rattani; Prof. Reza Derakhshani </li></br>
<li><b>Multi-task Learning For Detecting and Segmenting Manipulated Facial Images and Videos.</b></br>
          Huy Nguyen; Fuming Fang; Junichi Yamagishi; Isao Echizen </li></br>
<li><b>Attribute-Guided Coupled GAN for Cross-Resolution Face Recognition.</b></br>
          Veeru Talreja; Fariborz Taherkhani; Nasser Nasrabadi; Matthew Valenti </li></br>
<li><b>Zero-Shot Deep Hashing and Neural Network Based Error Correction for Face Template Protection.</b></br>
          Veeru Talreja; Matthew Valenti; Nasser Nasrabadi </li></br>
<li><b>Smartphone Camera De-identification while Preserving Biometric Utility.</b></br>
          Sudipta Banerjee; Arun Ross</li></br>
<li><b>Face Phylogeny Tree: Deducing Relationships Between Near Duplicate Face Images Using Legendre Polynomials and Radial Basis Functions.</b></br>
          Sudipta Banerjee; Arun Ross </li></br>
<li><b>Facial Attribute Classification: A Comprehensive Study and a Novel Mid-Level Fusion Classifier.</b></br>
          Abdulaziz  A Alorf; A Lynn Abbott; Kadir Peker</li></br>
<li><b>MasterPrint Attack Resistance: A Maximum Cover based Approach for Automatic Fingerprint Template Selection.</b></br>
         Aditi Roy; Nasir Memon; Arun Ross</li></br>
<li><b>Hierarchical Bloom Filter Framework for Security, Space-efficiency, and Rapid Query Handling in Biometric Systems.</b></br>
          Sumaiya Shomaji; Fatemah Ganji; Damon L Woodard; Domenic Forte </li></br>
<li><b>Subclass Contrastive Loss for Injured Face Recognition.</b></br>
          Puspita Majumdar; Saheb Chhabra; Richa Singh; Mayank Vatsa </li></br>
<li><b>Defending Against Adversarial Iris Examples Using Wavelet Decomposition.</b></br>
          Sobhan Soleymani; Ali Dabouei; Jeremy Dawson; Nasser Nasrabadi </li></br>
<li><b>A Locality Sensitive Hashing Based Approach for Generating Cancelable Fingerprints Templates.</b></br>
          Debanjan Sadhya; Zahid Akhtar; Dipankar Dasgupta </li></br>
<li><b>On Learning Joint Multi-biometric Representations by Deep Fusion.</b></br>
          Naser Damer ; Kristiyan Dimitrov ; Andreas Braun; Arjan Kuijper  </li></br>
<li><b>IARPA Janus Benchmark Multi-Domain Face.</b></br>
          Nathan D Kalka; James A Duncan; Jeremy Dawson; Charles Otto </li></br>
<li><b>Morton Filters for Iris Template Protection - An Incremental and Superior Approach Over Bloom Filters.</b></br>
          Kiran Raja; Raghavendra Ramachandra; Christoph Busch  </li></br>

</ul>
          </p>
          <div>
        </div>
     </section>
   </br>

       <section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="cfd">
          <div class="section-header" >
          <h2 style="text-align: center;">CALL FOR DEMONSTRATIONS</h2>
          </div>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">The 2019 IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS 2019) is pleased to invite researchers from both academia and industry to submit a proposal to present demonstrations of their research results. This provides a unique opportunity for researchers from academia and industry to showcase their work in front of BTAS 2019 attendees. Note that, BTAS 2019 is co-located with Federal Identity Forum and Exposition (FedID-2019). <br/><br/>

Demonstrations are not limited to the academic papers accepted to BTAS 2019. Demonstrations will be held in parallel with poster sessions during the Conference (September 23-26, 2019). <br/><br/>

Interested demo applicants can send the one-page proposal electronically to Demonstrationchairs (email:raghavendra.ramachandra@ntnu.no, john@mdtf.org) <br/><br/>
For more information contact Demonstration Chairs: Raghavendra Ramachandra (raghavendra.ramachandra@ntnu.no) and John J Howard (john@mdtf.org) <br/>
<ul><li><b >Dates:</b></li>
<ul>
<li>Demo proposal submission: 10th August 2019</li>
<li>Demo acceptance notification: 30th August 2019</li></ul></ul></p>
          <div>
        </div>
     </section>
   </br>

   
   <section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="com1">
          <div class="section-header" >
          <h2 style="text-align: center;">COMPETITIONS</h2>
          </div>
            
             <h2 style="color: #0e1b4d ; font-size: 25px; text-align: center;"><a href="https://sites.google.com/site/rtdrc2019/">Robust Tattoo Detection and Retrieval Competition (RTDRC 2019)</a></h2>
             <h2 style="color: #0e1b4d ; font-size: 20px; padding-left: 13px;"><b>Organizers:</b> Prof. Shiguang Shan, A/Prof.  Hu Han, Dr Abhijit Das, Dr Antitza Dantcheva</h2>

            <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">Despite the enormous progress in biometrics-based primary modalities such as the face, iris and fingerprint, unimodal biometrics identification has not been accepted in forensics [5, 6]. Tattoos, which constitute a pertinent and highly distinctive soft biometric trait, can be particularly useful in describing wanted or missing people, or even unidentified bodies. Hence, tattoos are highly instrumental in person identification. Consequently, research on tattoo-based biometrics has gained significant interest in the last few years. In order to explore the potential of tattoos, various research directions have been proposed in the literature. However, existing tattoo search methods or tattoo retrieval techniques mainly focus on the matching of cropped tattoos. Therefore, these topics require more analysis. Open research problems include tattoo detection, as well as localization, i.e., determining whether an image contains a tattoo and if so, segmentation of the tattoo.
            </br>
            </br>
            In addition, Sketch-Based Tattoo Search can be instrumental in many scenarios, e.g., if the surveillance image of a crime scene is not available, and the query is a tattoo sketch, drawn based a witness description. Therefore, it is important to evaluate the matching performance in similar scenarios.
            </br>
            </br>
            We note that tattoo detection retrieval techniques can get highly affected by the change in sample quality, acquisition technique, etc. Motivated by the past competition on tattoo biometrics, namely Tatt-C and Tatt-E, and to further advance associated research, we host this competition focusing on the robustness of the evaluation pertained to tattoo detection and retrieval methodologies involving cross-dataset evaluation. The competition will focus on the following three tasks: (i) tattoo detection, (ii) tattoo retrieval, and (iii) tattoo sketch-based retrieval</p>
          <div>
        </div>
      </section>
      </br>

      <section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="doctoral">
          <div class="section-header" >
          <h2 style="text-align: center;">DOCTORAL CONSORTIUM</h2>
          </div>
          <p style="color: #0e1b4d ; font-size: 18px; padding-left: 13px; text-align: ;">Call for Participation for the <a href="templates/doc.pdf">Doctoral Consortium</a>!!!</p>
<p><ul><li>Important Dates:</li>
<ul><li>
          Submission deadline: July 15, 2019 </li>
<li>Notification of acceptance: August 1, 2019</li></ul></ul></p>
          <div>
        </div>
     </section>
   </br>

      <!-- <section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="mainc">
          <div class="section-header" >
          <h2 style="text-align: center;">MAIN CONFERENCE</h2>
          </div>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">To be announced...</p>
          <div>
        </div>
     </section>
   </br> -->
<section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="cfp">
          <div class="section-header" >
          <h2 style="text-align: center;">Special Session - Call for papers</h2>
          </div>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b style="text-align: middle;">Special Session On Generalizability and Adaptability in Biometrics (GAPinB)</b> <br/><br/>

The challenges of generalization of algorithms and solutions in biometrics has been a long-standing but critical problem. The advancements in biometric solutions have achieved very high accuracy for various problems on databases investigated for the relative problem. However, the recent works have pointed the deficiencies in scaling of such algorithms across databases and sensors. The problem is persistently seen for identification and verification across cross-spectral data, attack detection across variety of data. The limited scalability of the algorithms needs newer and robust solutions to make the biometric systems adaptable for various kind of data. BTAS-2019 - Special session on Generalizability in Biometrics is organized to evaluate the impact and mitigation measures of such generalization problems in
biometric systems. This half-day special session in conjunction with BTAS-2019, calls for high-quality, previously unpublished works
related to approaches and methodologies. <br/><br/>

<b>Submission Guidelines:</b><br/>
Submissions should confirm to the BTAS-2019 proceedings style.
Accepted papers from the Special Session will be included in the
BTAS2019 Proceedings through IEEE. Authors are invited to submit
full-length papers (up to 4 pages for technical content including
figures and references, and one optional 5th page containing only
references). Papers must be submitted online through the
submission system (see below) and will be double-blind peer
reviewed by at least three reviewers. The submission template with

instruction can be found at: https://sites.google.com/view/btas-
gapinb/home

Please submit your papers at:
https://cmt3.research.microsoft.com/BTASSS2019 (Available
from 5th July 2019) <br/><br/>

<b>Topics (not limited to):</b>
<ul><li>Novel algorithms for identification and verification solutions across heterogeneous data</li>
<li>Attack detection mechanisms for heterogeneous data</li>
<li>Cross-sensor scalability issues in biometrics</li>
<li>Cross-database attack (e.g., spoofing/presentation attack) detection mechanisms</li>
<li>CNNs for generalizability solutions</li>
</ul>
<b>Important Dates:</b>
<ul><li>Special Session: 23 Sep 2019</li>
<li>Full Paper Submission: 15 July 2019</li>
<li>Acceptance Notice: 15 Aug 2019</li>
<li>Camera-Ready Paper: 10 Sep 2019</li></ul>
<b>Special Session Chairs:</b>
<ol><li>Prof. Davide Maltoni, UBO, Italy</li>
<li>Prof. Raymond Veldhuis, UTW, Netherlands</li>
<li>Prof. Christoph Busch, NTNU, Norway</li></ol>
<b>Organizing Committee:</b>
<ol><li>Prof. Raghavendra Ramachandra, NTNU, Norway</li>
<li>Assoc. Prof. Matteo Ferrara, UBO, Italy</li>
<li>Assoc. Prof. Kiran Raja, NTNU, Norway</li>
<li>Dr. Naser Damer, Fraunhofer IGD, Germany</li></ol>
<b>Further details:</b> https://sites.google.com/view/btas-gapinb/home

</p>
          <div>
        </div>
     </section>
   </br>


      <section id="speakers" class="section-with-bg wow fadeInUp">
        <div class="container" >
         <div id ="tutorials">
          <div class="section-header" >
          <h2 style="text-align: center;">TUTORIALS</h2>
          </div>
<h3>Tutorial Schedule:</h3>
          <ul>
            <li>9:00 – 12:30 Tutorial I: Recent Advances in Heterogeneous Face Recognition (HFR):
Infrared-to-Visible Matching</li>
<li>9:00 – 12:30 Tutorial II:  Estimation of Soft-biometrics from fingerprints </li>
<li>2:00 - 5:30 PM Tutorial III:  Face Anti-Spoofing: Past, Present and the Future</li>
          </ul>
        </br><hr>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Title:</b> Recent Advances in Heterogeneous Face Recognition (HFR): Infrared-to-Visible Matching
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Speakers:</b> Cunjian Chen (Michigan State University), Shuowen (Sean) Hu (U.S. Army Research Laboratory, Ben Riggan (University of Nebraska-Lincoln), Nathaniel J. Short, (Booz Allen Hamilton), and Vishal M. Patel (Johns Hopkins University)
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;"><b>Abstract:</b> This tutorial will address the recent advancements for the emerging research area of heterogeneous face recognition (HFR) from mainly an academic perspective but with insights from government and industry, which seeks to match facial probe imagery acquired in one modality against a gallery database of facial images acquired in another modality. HFR has strong potential to provide new capabilities for law enforcement, the military, and the intelligence community. In this tutorial, we will focus on infrared-to-visible face recognition for low- light and nighttime applications, discussing feature extraction techniques, regression methods, and classification algorithms for matching infrared imagery to gallery databases containing only visible imagery. We will also present recent advances in exploiting sensor technology such as polarimetric imaging for HFR and discuss new algorithms such as generative adversarial network-based approaches for HFR.
          </p>
          <hr>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Title:</b> Estimation of Soft Biometrics from Fingerprints
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Speakers:</b> Emanuela Marasco (George Mason University) and Larry Tang (George Mason University)
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;"><b>Abstract:</b> Accurate gender prediction brings benefits to several applications such as content-based indexing, security, forensics and intelligence applications. A gender recognizer can be combined with the output of primary identifiers to increase the recognition accuracy in challenging scenarios (e.g., partial evidence). In crime investigations, gender classification may minimize the list of suspects. Although the development of reliable gender estimators is needed, existing approaches involving traditional ridge-based fingerprint data are only 80% accurate, and often the processes are not fully automated. Research studies have shown that females exhibit a higher ridge density compared to males, due to finer epidermal ridge details. Thus, the local texture of a fingerprint is expected to offer gender cues because it can encode the ridge density structure that varies between males and females. Local textural descriptors such as Local Binary Patterns (LBP), Local Phase Quantization (LPQ) and Binarized Statistical Image Features (BSIF) have been found to be successful for this task in both high quality and degraded fingerprint images. Differences between males and females were also captured in the frequency domain through Fourier analysis and Discrete Wavelet Transform. Recent studies have explored gender signature on a small and well-defined partition of a fingerprint corresponding to the single minutiae. This methodology is able to deal well with partial fingerprints. Furthermore, given that biometric data is gathered from different sensors, analyzing the sensitivity of the feature set to device changes becomes important. In this regard, local textural descriptors have shown robustness with respect to capture bias. Additionally, logistic regression models were applied to identify the significant features for gender estimation. These models exploit quality-based NFIQ2 features as well as local texture.</br>
            This tutorial aims at bringing awareness about the ongoing research in Gender estimation
from fingerprints and the challenges faced in improving the prediction accuracy. We will
review the various experiments carried out, the several features extracted from fingerprints,
classification models used and their efficiency in classifying gender.
          </p>
          <hr>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Title:</b> Face Anti-Spoofing: Past, Present and the Future
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;">
            <b>Speakers:</b> Yaojie Liu (Michigan State University) and Xiaoming Liu (Michigan State University)
          </p>
          <p style="color: #0e1b4d ; font-size: 16px; padding-left: 13px; text-align: ;"><b>Abstract:</b> Face is one of the most popular biometric modalities due to its convenience of usage in access control, phone unlock and etc. Despite the high recognition accuracy, face recognition systems are not designed to distinguish between real human faces and fake ones, e.g., photograph, screen. Face spoof attacks, or presentation attacks, are the real-world attacks that use those fake faces to deceive the systems to recognize them as the real live person. Thus, to safely utilizing face recognition systems, face anti-spoofing techniques
          are crucial in detecting spoof attacks before performing recognition.</br>
This tutorial provides a comprehensive review of the development of face anti-spoofing technologies. We focus on solutions for RGB sensors and include discussions of various spoof attacks (e.g. print attack, replay attack, and 3D mask attack), existing databases (e.g CASIAMFSD, OULU-NPU, HKBU MAR, and SiW), and representative works (e.g. conventional approaches and deep learning-based approaches). We also plan to discuss hardware solutions (e.g. NIR, and depth camera), generalizability to unknown attacks, several practical tips of building a face anti-spoofing system, and future research directions for face anti-spoofing.
          </p>
          <div>
        </div>
     </section>
   </br>
   </div>
   </div> 
</main>
  
  


  <!--==========================
    Footer
  ============================-->
  <!-- <footer id="footer">
    <div class="footer-top">
      <div class="container">
        <div class="row">

          <div class="col-lg-3 col-md-6 footer-info">
            <img src="img/logo.png" alt="TheEvenet">
            <p>In alias aperiam. Placeat tempore facere. Officiis voluptate ipsam vel eveniet est dolor et totam porro. Perspiciatis ad omnis fugit molestiae recusandae possimus. Aut consectetur id quis. In inventore consequatur ad voluptate cupiditate debitis accusamus repellat cumque.</p>
          </div>

          <div class="col-lg-3 col-md-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="fa fa-angle-right"></i> <a href="#">Home</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">About us</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Services</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Terms of service</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Privacy policy</a></li>
            </ul>
          </div>

          <div class="col-lg-3 col-md-6 footer-links">
            <h4>Useful Links</h4>
            <ul>
              <li><i class="fa fa-angle-right"></i> <a href="#">Home</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">About us</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Services</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Terms of service</a></li>
              <li><i class="fa fa-angle-right"></i> <a href="#">Privacy policy</a></li>
            </ul>
          </div>

          <div class="col-lg-3 col-md-6 footer-contact">
            <h4>Contact Us</h4>
            <p>
              A108 Adam Street <br>
              New York, NY 535022<br>
              United States <br>
              <strong>Phone:</strong> +1 5589 55488 55<br>
              <strong>Email:</strong> info@example.com<br>
            </p>
 -->
            <!-- <div class="social-links">
              <a href="#" class="twitter"><i class="fa fa-twitter"></i></a>
              <a href="#" class="facebook"><i class="fa fa-facebook"></i></a>
              <a href="#" class="instagram"><i class="fa fa-instagram"></i></a>
              <a href="#" class="google-plus"><i class="fa fa-google-plus"></i></a>
              <a href="#" class="linkedin"><i class="fa fa-linkedin"></i></a>
            </div> -->

          <!-- </div>

        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong>TheEvent</strong>. All Rights Reserved
      </div>
      <div class="credits"> -->
        <!--
          All the links in the footer should remain intact.
          You can delete the links only if you purchased the pro version.
          Licensing information: https://bootstrapmade.com/license/
          Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=TheEvent
        -->
       <!--  Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>
  </footer> --><!-- #footer -->

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>

  <!-- Contact Form JavaScript File -->
  <script src="contactform/contactform.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js"></script>
</body>

</html>
  